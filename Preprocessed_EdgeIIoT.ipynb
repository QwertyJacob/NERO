{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca5cd0f1-590d-49ce-9086-7e7ad55f98ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df4bc2-2dc3-49e1-94c7-b40b90325a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from connect import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d3607f-0c58-48da-9267-5b8785d7298b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bb3b5f-dc7f-4df5-a382-4c6120ee58b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import NAR.utils as utils\n",
    "import NAR.data_management as dm\n",
    "import NAR.plotting_utils as pu\n",
    "import NAR.masking as masking\n",
    "import NAR.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058da714-78cb-42e6-9d69-e38f36ade4ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Reload modules (DEV):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805529e4-73fb-4ac0-9124-d72b08aa7994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reload_modules([utils, dm, pu, masking, models])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711fdca5-ac7a-459a-a840-702f17a24f9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Checkpoint:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a435c133-8228-452c-9675-a163ff954463",
   "metadata": {},
   "source": [
    "### Edge to IIoT set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a91ea2-919c-4ed0-90ea-553941f5bdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    '../../../../nfs/jcevallos/datasets/edge-iiot/preprocessed/preprocessed-edge-iiotset.csv',\n",
    "    low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4ee6b0-320a-4825-ba67-7844987e0f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.drop(['Attack_label', 'attack_macro_cat', 'Attack_type'], axis=1)\n",
    "y = df['Attack_type']\n",
    "\n",
    "categorical_indicator = X.dtypes == 'O'\n",
    "\n",
    "categorical_columns = X.columns[list(np.where(np.array(categorical_indicator)==True)[0])].tolist()\n",
    "cont_columns = list(set(X.columns.tolist()) - set(categorical_columns))\n",
    "\n",
    "cat_idxs = list(np.where(np.array(categorical_indicator)==True)[0])\n",
    "con_idxs = list(set(range(len(X.columns))) - set(cat_idxs))\n",
    "\n",
    "# Categories and target classes to natural numbers:\n",
    "cat_dims = []\n",
    "for col in categorical_columns:\n",
    "    l_enc = LabelEncoder()\n",
    "    X[col] = l_enc.fit_transform(X[col].values)\n",
    "    cat_dims.append(len(l_enc.classes_))\n",
    "\n",
    "X = X.values\n",
    "y = y.values\n",
    "l_enc = LabelEncoder()\n",
    "y = l_enc.fit_transform(y)\n",
    "\n",
    "# num of classes:\n",
    "y_dim = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cb49f2-ac00-45fa-8dc8-d9b4dff99f3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converting to suitable format:\n",
    "data = pd.DataFrame(X)\n",
    "data['Label'] = l_enc.inverse_transform(y)\n",
    "\n",
    "# zdas:\n",
    "zdas = ['SQL_injection', 'Uploading',\n",
    "        'Vulnerability_scanner', 'XSS']\n",
    "zdas\n",
    "train_zdas = ['SQL_injection', 'Uploading']\n",
    "test_zdas = ['Vulnerability_scanner', 'XSS']\n",
    "test_only_knowns = ['Backdoor', 'DDoS_HTTP']\n",
    "\n",
    "# Masking:\n",
    "data = masking.mask_generic_data(\n",
    "    data=data,\n",
    "    zdas=zdas,\n",
    "    )\n",
    "\n",
    "train_data, test_data = masking.split_real_data_gen_zda(\n",
    "    data=data,\n",
    "    train_zdas=train_zdas,\n",
    "    test_zdas=test_zdas,\n",
    "    test_only_knowns=test_only_knowns\n",
    "    )\n",
    "\n",
    "classes = data['Label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa9a7b3-ab0a-4133-8c27-2fc2bf626c31",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999b41cf-4e0e-4ff8-a915-ab78ef737cc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## helper code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd8e43c-c1a1-4228-8d98-60bb6d378981",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_stuff(prefix):\n",
    "    torch.save(\n",
    "        encoder.state_dict(),\n",
    "        prefix+'enc.pt')\n",
    "    torch.save(\n",
    "        decoder_1_b.state_dict(),\n",
    "        prefix+'_dec_b.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bc7dc5-62bb-4a98-80fc-a445b34a9c63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def first_phase_simple(\n",
    "        sample_batch):\n",
    "\n",
    "    global cs_cm_1\n",
    "    global os_cm_1\n",
    "    global metrics_dict\n",
    "\n",
    "    # get masks: THESE ARE NOT COMPLEMETARY!\n",
    "    zda_mask, \\\n",
    "        known_classes_mask, \\\n",
    "        unknown_1_mask, \\\n",
    "        active_query_mask = utils.get_gennaro_masks(\n",
    "            sample_batch[1],\n",
    "            N_QUERY,\n",
    "            device=device)\n",
    "\n",
    "    # get one_hot_labels:\n",
    "    oh_labels = utils.get_oh_labels(\n",
    "        decimal_labels=sample_batch[1][:, 0].long(),\n",
    "        total_classes=max_prototype_buffer,\n",
    "        device=device)\n",
    "\n",
    "    # mask labels:\n",
    "    oh_masked_labels = utils.get_one_hot_masked_labels(\n",
    "        oh_labels,\n",
    "        unknown_1_mask,\n",
    "        device=device)\n",
    "\n",
    "    # encoding input space:\n",
    "    encoded_inputs = encoder(\n",
    "        sample_batch[0].float())\n",
    "\n",
    "    # processing\n",
    "    decoded_1, hiddens_1, predicted_kernel = processor_1(\n",
    "        encoded_inputs,\n",
    "        oh_masked_labels)\n",
    "\n",
    "    # semantic kernel:\n",
    "    semantic_kernel = oh_labels @ oh_labels.T\n",
    "    # Processor regularization:\n",
    "    proc_1_reg_loss = utils.get_kernel_kernel_loss(\n",
    "        semantic_kernel,\n",
    "        predicted_kernel,\n",
    "        a_w=attr_w,\n",
    "        r_w=rep_w)\n",
    "\n",
    "    # Transform lables for Few_shot Closed-set classif.\n",
    "    # compatible with the design of models.get_centroids functions,\n",
    "    # wich is called by our GAT processors.\n",
    "    unique_labels, transformed_labels = sample_batch[1][:, 0][active_query_mask].unique(\n",
    "        return_inverse=True)\n",
    "\n",
    "    # closed set classification\n",
    "    dec_1_loss_a = decoder_1a_criterion(\n",
    "        decoded_1[active_query_mask],\n",
    "        transformed_labels)\n",
    "\n",
    "    # Detach closed from open set gradients\n",
    "    input_for_os_dec = decoded_1.detach()\n",
    "    input_for_os_dec.requires_grad = True\n",
    "\n",
    "    # Unknown cluster prediction:\n",
    "    predicted_unknown_1s = decoder_1_b(\n",
    "        scores=input_for_os_dec[unknown_1_mask]\n",
    "        )\n",
    "\n",
    "    # open-set loss:\n",
    "    dec_1_loss_b = decoder_1b_criterion(\n",
    "        predicted_unknown_1s,\n",
    "        zda_mask[unknown_1_mask].float().unsqueeze(-1))\n",
    "\n",
    "    # inverse transform cs preds\n",
    "    it_preds = utils.inverse_transform_preds(\n",
    "        transormed_preds=decoded_1[active_query_mask],\n",
    "        real_labels=unique_labels,\n",
    "        real_class_num=max_prototype_buffer)\n",
    "\n",
    "    #\n",
    "    # REPORTING:\n",
    "    #\n",
    "\n",
    "    # Closed set confusion matrix\n",
    "    cs_cm_1 += utils.efficient_cm(\n",
    "        preds=it_preds.detach(),\n",
    "        targets=sample_batch[1][:, 0][active_query_mask].long())\n",
    "\n",
    "    # Open set confusion matrix\n",
    "    os_cm_1 += utils.efficient_os_cm(\n",
    "        preds=(predicted_unknown_1s.detach() > 0.5).long(),\n",
    "        targets=zda_mask[unknown_1_mask].long()\n",
    "        )\n",
    "\n",
    "    # accuracies:\n",
    "    CS_acc = utils.get_acc(\n",
    "        logits_preds=it_preds,\n",
    "        oh_labels=oh_labels[active_query_mask])\n",
    "\n",
    "    OS_acc = utils.get_binary_acc(\n",
    "        logits=predicted_unknown_1s.detach(),\n",
    "        labels=zda_mask[unknown_1_mask].float().unsqueeze(-1))\n",
    "\n",
    "    OS_b_acc = utils.get_balanced_accuracy(\n",
    "                os_cm=os_cm_1,\n",
    "                n_w=balanced_acc_n_w\n",
    "                )\n",
    "\n",
    "    # for reporting:\n",
    "    metrics_dict['losses_1a'].append(dec_1_loss_a.item())\n",
    "    metrics_dict['proc_reg_loss1'].append(proc_1_reg_loss.item())\n",
    "    metrics_dict['CS_accuracies'].append(CS_acc.item())\n",
    "    metrics_dict['losses_1b'].append(dec_1_loss_b.item())\n",
    "    metrics_dict['OS_accuracies'].append(OS_acc.item())\n",
    "    metrics_dict['OS_B_accuracies'].append(OS_b_acc.item())\n",
    "\n",
    "    # Processor loss:\n",
    "    proc_1_loss = dec_1_loss_a + proc_1_reg_loss\n",
    "\n",
    "    return proc_1_loss, \\\n",
    "        dec_1_loss_b, \\\n",
    "        hiddens_1, \\\n",
    "        decoded_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d118e201-21e9-454c-9837-93f705a9195c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## init data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c48d63b9-982b-4e04-ad2b-bb0d8271a971",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save = True\n",
    "wb = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab974a58-3d4f-4ed8-90ef-433225757430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate Data\n",
    "torch_seed = 1234\n",
    "torch.manual_seed(torch_seed)\n",
    "np.random.seed(42)  # Few Shot sampling uses np.random to choose classes...\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "# Initialize\n",
    "#\n",
    "#\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Dataset and Dataloader:\n",
    "train_dataset = dm.Simple_Dataset(\n",
    "    features=train_data.drop(columns=[\n",
    "        'Label',\n",
    "        'ZdA']).values,\n",
    "    df=train_data)\n",
    "\n",
    "test_dataset = dm.Simple_Dataset(\n",
    "    features=test_data.drop(columns=[\n",
    "        'Label',\n",
    "        'ZdA']).values,\n",
    "    df=test_data)\n",
    "\n",
    "# Number of classes per task :\n",
    "# two of them are ZdAs, one is a type B and the other a type A\n",
    "N_WAY = 5\n",
    "N_SHOT = 5   # Number of samples per class in the support set\n",
    "N_QUERY = 20  # Number of samples per class in the query set\n",
    "\n",
    "n_train_tasks = 500    # For speedy tests, reduce here...\n",
    "n_eval_tasks = 50     # For speedy tests, reduce here...\n",
    "\n",
    "\n",
    "num_of_test_classes = len(test_dataset.classes)\n",
    "num_of_train_classes = len(train_dataset.classes)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    sampler=dm.FewShotSampler_Simple(\n",
    "                dataset=train_dataset,\n",
    "                n_tasks=n_train_tasks,\n",
    "                classes_per_it=N_WAY,\n",
    "                k_shot=N_SHOT,\n",
    "                q_shot=N_QUERY),\n",
    "    num_workers=10,\n",
    "    drop_last=True,\n",
    "    collate_fn=dm.convenient_cf)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    sampler=dm.FewShotSampler_Simple(\n",
    "                dataset=test_dataset,\n",
    "                n_tasks=n_eval_tasks,\n",
    "                classes_per_it=N_WAY,\n",
    "                k_shot=N_SHOT,\n",
    "                q_shot=N_QUERY),\n",
    "    num_workers=10,\n",
    "    drop_last=True,\n",
    "    collate_fn=dm.convenient_cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1db0a7-93b7-403d-92ec-b9bb22959cad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## init architectures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0fd612f-906b-4168-9bb8-bddad2a06cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/project_1/code/notebooks/models/wandb/run-20231219_171544-gfv7pmn5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jfcevallos/Nero_1.1/runs/gfv7pmn5' target=\"_blank\">EdgeIIoTset from scratch</a></strong> to <a href='https://wandb.ai/jfcevallos/Nero_1.1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jfcevallos/Nero_1.1' target=\"_blank\">https://wandb.ai/jfcevallos/Nero_1.1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jfcevallos/Nero_1.1/runs/gfv7pmn5' target=\"_blank\">https://wandb.ai/jfcevallos/Nero_1.1/runs/gfv7pmn5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###\n",
    "# Hyper params:\n",
    "###\n",
    "max_prototype_buffer = 15\n",
    "lr = 0.001\n",
    "# training parameters\n",
    "n_epochs = 120\n",
    "norm = \"batch\"\n",
    "dropout = 0.1\n",
    "patience = 40\n",
    "lambda_os = 1\n",
    "\n",
    "processor_attention_heads = 8\n",
    "h_dim = 1024\n",
    "report_step_frequency = 100\n",
    "pos_weight = 5\n",
    "architectures = 'GATV5 Confidence Dec'\n",
    "balanced_acc_n_w = 0.5\n",
    "attr_w = 1\n",
    "rep_w = 1\n",
    "natural_inputs_dim = 46\n",
    "run_name = f'EdgeIIoTset from scratch'\n",
    "\n",
    "if wb:\n",
    "    wandb.init(project='Nero_1.1',\n",
    "               name=run_name,\n",
    "               config={\"N_SHOT\": N_SHOT,\n",
    "                       \"N_QUERY\": N_QUERY,\n",
    "                       \"N_WAY\": N_WAY,\n",
    "                       \"num_of_test_classes\": num_of_test_classes,\n",
    "                       \"num_of_train_classes\": num_of_train_classes,\n",
    "                       \"train_batch_size\": iter(train_loader).__next__()[0].shape[0],\n",
    "                       \"len(train_loader)\": len(train_loader),\n",
    "                       \"len(test_dataset)\": len(test_dataset),\n",
    "                       \"max_prototype_buffer\": max_prototype_buffer,\n",
    "                       \"device\": device,\n",
    "                       \"natural_inputs_dim\": natural_inputs_dim,\n",
    "                       \"h_dim\": h_dim,\n",
    "                       \"lr\": lr,\n",
    "                       \"n_epochs\": n_epochs,\n",
    "                       \"norm\": norm,\n",
    "                       \"dropout\": dropout,\n",
    "                       \"patience\": patience,\n",
    "                       'zdas': data[data.ZdA == True]['Label'].unique(),\n",
    "                       \"lambda_os\": lambda_os,\n",
    "                       \"positive_weight\": pos_weight,\n",
    "                       \"architectures\": architectures,\n",
    "                       \"balanced_acc_n_w\": balanced_acc_n_w,\n",
    "                       \"attr_w\": attr_w,\n",
    "                       \"rep_w\": rep_w\n",
    "                       })\n",
    "else:\n",
    "    print(run_name)\n",
    "\n",
    "# Encoder\n",
    "encoder = models.Encoder(\n",
    "    in_features=natural_inputs_dim,\n",
    "    out_features=h_dim,\n",
    "    norm=norm,\n",
    "    dropout=dropout,\n",
    "    ).to(device)\n",
    "\n",
    "# First phase:\n",
    "processor_1 = models.GAT_V5_Processor(\n",
    "                h_dim=h_dim,\n",
    "                processor_attention_heads=processor_attention_heads,\n",
    "                dropout=dropout,\n",
    "                device=device\n",
    "                ).to(device)\n",
    "\n",
    "decoder_1a_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "decoder_1_b = models.Confidence_Decoder(\n",
    "                in_dim=N_WAY-1,  # Subtract 1 ZdA\n",
    "                dropout=dropout,\n",
    "                device=device\n",
    "                ).to(device)\n",
    "\n",
    "decoder_1b_criterion = nn.BCEWithLogitsLoss(\n",
    "    pos_weight=torch.Tensor([pos_weight])).to(device)\n",
    "\n",
    "\n",
    "params_for_processor_optimizer = \\\n",
    "        list(encoder.parameters()) + \\\n",
    "        list(processor_1.parameters())\n",
    "\n",
    "processor_optimizer = optim.Adam(\n",
    "    params_for_processor_optimizer,\n",
    "    lr=lr)\n",
    "\n",
    "os_optimizer = optim.Adam(\n",
    "    decoder_1_b.parameters(),\n",
    "    lr=lr)\n",
    "\n",
    "\n",
    "# TRAINING\n",
    "max_eval_TNR = torch.zeros(1, device=device)\n",
    "epochs_without_improvement = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52732bd3-fde9-43ef-a087-fd4ddb11527d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.watch(processor_1)\n",
    "wandb.watch(encoder)\n",
    "wandb.watch(decoder_1_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d3eeb4-edb8-499a-a8ad-c24bf70f417e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train (from scratch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52b0b122-cf1c-4379-b336-11d9da649979",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3de2e5d78f4be58f1e62c254cb47b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at episode 39806203\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3221757778814af6abf419cb59dd5d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='30.189 MB of 30.189 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>CS1 accuracy_eval: </td><td>▁▆▅▆▆▇▆▅▇▅▆▆▆▆▅▄▅▆▆▇▅█▆▁▅█▅▆▅▅▄▅▆▆▆▆▆▆</td></tr><tr><td>CS1 accuracy_train: </td><td>▁▅▅▅▅▆▅▅▅▆▅▆▆█▆▅▅▅▅▅▅▅▅▅▅▅▆▅▅▅▆▅▅▆▅▅▆▅▅▆</td></tr><tr><td>Early stopping at episode</td><td>▁</td></tr><tr><td>OS1 Bal. accuracy_eval: </td><td>█▄▅▃▂▄▃▂▂▃▄▄▃▄▄▂▃▄▂▇▃▆▂▄▅█▄▆▄▄▃▁▄▅▄▄▄▅</td></tr><tr><td>OS1 Bal. accuracy_train: </td><td>▁▆▆▆▆▆▆▇▇█▇▅▇▅▇█▇▇▇▇▇▇▇▇█▇▇▇█▇█▇█▇██████</td></tr><tr><td>OS1 accuracy_eval: </td><td>█▃▃▅▁▄▃▄▃▂▅▃▃▁▃▄▃▄▃▇▃▄▁▆▅█▃▄▅▂▃▃▄▃▄▃▂▄</td></tr><tr><td>OS1 accuracy_train: </td><td>▁▇▅▆▇▇█████▇█▇██████████████████████████</td></tr><tr><td>epoch: </td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>mean dec_1_loss_a_eval: </td><td>▃▂▂▂▂▂▄▂▂▃▂▂▂▃▅▅▂▅▄▁▂▁▂▅▃▁▃▃▃▃▃▅▂█▂▂▂▃</td></tr><tr><td>mean dec_1_loss_a_train: </td><td>█▇▆▆▄▃▂▂▂▂▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mean dec_1_loss_b_eval: </td><td>█▇▅▄▇▅▅▅▅▆▄▅▅▄▄▅▅▄▆▁▅▃▆▃▃▁▄▄▄▅▅▅▄▄▄▅▅▃</td></tr><tr><td>mean dec_1_loss_b_train: </td><td>█▇▆▅▃▃▃▂▂▂▂▃▂▅▂▁▂▂▂▂▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mean proc_reg_loss1 eval: </td><td>▅▄▅▅▆▅▅▅▄▅▄▅▅▄▅▇▆▇▅▄▅▂▆█▅▁▅▅▅▆▇▆▅▅▅▄▅▅</td></tr><tr><td>mean proc_reg_loss1 train: </td><td>█▃▂▃▂▂▂▃▂▁▂▃▂▄▁▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▂▂▂▁▁▁▂▂</td></tr><tr><td>step: </td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▃▆▆▆▆▆▆▇▇▇▇▇███▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>CS1 accuracy_eval: </td><td>0.9234</td></tr><tr><td>CS1 accuracy_train: </td><td>0.9573</td></tr><tr><td>Early stopping at episode</td><td>39806203</td></tr><tr><td>OS1 Bal. accuracy_eval: </td><td>0.87775</td></tr><tr><td>OS1 Bal. accuracy_train: </td><td>0.87822</td></tr><tr><td>OS1 accuracy_eval: </td><td>0.89037</td></tr><tr><td>OS1 accuracy_train: </td><td>0.88423</td></tr><tr><td>epoch: </td><td>81</td></tr><tr><td>mean dec_1_loss_a_eval: </td><td>0.69592</td></tr><tr><td>mean dec_1_loss_a_train: </td><td>0.13226</td></tr><tr><td>mean dec_1_loss_b_eval: </td><td>1.02689</td></tr><tr><td>mean dec_1_loss_b_train: </td><td>1.02473</td></tr><tr><td>mean proc_reg_loss1 eval: </td><td>87.93</td></tr><tr><td>mean proc_reg_loss1 train: </td><td>86.14986</td></tr><tr><td>step: </td><td>39806200</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">EdgeIIoTset from scratch</strong> at: <a href='https://wandb.ai/jfcevallos/Nero_1.1/runs/gfv7pmn5' target=\"_blank\">https://wandb.ai/jfcevallos/Nero_1.1/runs/gfv7pmn5</a><br/>Synced 7 W&B file(s), 656 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231219_171544-gfv7pmn5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in tqdm(range(n_epochs)):\n",
    "\n",
    "    # TRAIN\n",
    "    encoder.train()\n",
    "    processor_1.train()\n",
    "    decoder_1_b.train()\n",
    "\n",
    "    # reset conf Mats\n",
    "    cs_cm_1 = torch.zeros(\n",
    "        [max_prototype_buffer, max_prototype_buffer],\n",
    "        device=device)\n",
    "    os_cm_1 = torch.zeros([2, 2], device=device)\n",
    "\n",
    "    # reset metrics dict\n",
    "    metrics_dict = utils.reset_metrics_dict()\n",
    "\n",
    "    # go!\n",
    "    for batch_idx, sample_batch in enumerate(train_loader):\n",
    "        # go to cuda:\n",
    "        sample_batch = sample_batch[0].to(device), sample_batch[1].to(device)\n",
    "\n",
    "        # PHASE 1\n",
    "        proc_loss, \\\n",
    "            os_loss, \\\n",
    "            hiddens_1, \\\n",
    "            decoded_1 = first_phase_simple(\n",
    "                                sample_batch)\n",
    "\n",
    "        # Learning\n",
    "        processor_optimizer.zero_grad()\n",
    "        proc_loss.backward()\n",
    "        processor_optimizer.step()\n",
    "\n",
    "        os_loss = os_loss\n",
    "        os_optimizer.zero_grad()\n",
    "        os_loss.backward()\n",
    "        os_optimizer.step()\n",
    "\n",
    "        # Reporting\n",
    "        step = batch_idx + (epoch * len(train_loader))\n",
    "\n",
    "        if step % report_step_frequency == 0:\n",
    "            utils.reporting_gennaro(\n",
    "                'train',\n",
    "                epoch,\n",
    "                metrics_dict,\n",
    "                step,\n",
    "                wb,\n",
    "                wandb)\n",
    "\n",
    "    pu.super_plotting_function_gennaro(\n",
    "                phase='Training',\n",
    "                labels=sample_batch[1].cpu(),\n",
    "                hiddens_1=hiddens_1.detach().cpu(),\n",
    "                scores_1=decoded_1.detach().cpu(),\n",
    "                cs_cm_1=cs_cm_1.cpu(),\n",
    "                os_cm_1=os_cm_1.cpu(),\n",
    "                wb=wb,\n",
    "                wandb=wandb,\n",
    "                complete_classes=classes,\n",
    "                )\n",
    "\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        # Evaluation\n",
    "        encoder.eval()\n",
    "        processor_1.eval()\n",
    "        decoder_1_b.eval()\n",
    "\n",
    "        # reset conf Mats\n",
    "        cs_cm_1 = torch.zeros(\n",
    "            [max_prototype_buffer, max_prototype_buffer],\n",
    "            device=device)\n",
    "        os_cm_1 = torch.zeros([2, 2], device=device)\n",
    "\n",
    "        # reset metrics dict\n",
    "        metrics_dict = utils.reset_metrics_dict()\n",
    "\n",
    "        # go!\n",
    "        for batch_idx, sample_batch in enumerate(test_loader):\n",
    "            # go to cuda:\n",
    "            sample_batch = sample_batch[0].to(device), sample_batch[1].to(device)\n",
    "\n",
    "            # PHASE 1\n",
    "            proc_1_loss, \\\n",
    "                os_1_loss, \\\n",
    "                hiddens_1, \\\n",
    "                decoded_1 = first_phase_simple(\n",
    "                                    sample_batch)\n",
    "            # Reporting\n",
    "            step = batch_idx + (epoch * len(test_loader))\n",
    "\n",
    "            if step % report_step_frequency == 0:\n",
    "                utils.reporting_gennaro(\n",
    "                    'eval',\n",
    "                    epoch,\n",
    "                    metrics_dict,\n",
    "                    step,\n",
    "                    wb,\n",
    "                    wandb)\n",
    "\n",
    "        pu.super_plotting_function_gennaro(\n",
    "                phase='Evaluation',\n",
    "                labels=sample_batch[1].cpu(),\n",
    "                hiddens_1=hiddens_1.detach().cpu(),\n",
    "                scores_1=decoded_1.detach().cpu(),\n",
    "                cs_cm_1=cs_cm_1.cpu(),\n",
    "                os_cm_1=os_cm_1.cpu(),\n",
    "                wb=wb,\n",
    "                wandb=wandb,\n",
    "                complete_classes=classes,\n",
    "            )\n",
    "\n",
    "        # Checking for improvement\n",
    "        curr_TNR = np.array(metrics_dict['OS_B_accuracies']).mean()\n",
    "\n",
    "\n",
    "        if curr_TNR > max_eval_TNR:\n",
    "            max_eval_TNR = curr_TNR\n",
    "            epochs_without_improvement = 0\n",
    "            save_stuff(run_name+'_e'+str(epoch))\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f'Early stopping at episode {step}')\n",
    "            if wb:\n",
    "                wandb.log({'Early stopping at episode': step})\n",
    "            break\n",
    "\n",
    "if wb:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9831d3-5748-4ac4-9240-2079d5b83c2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa5175f-df7d-4cb8-a0e6-40994c8f5b9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Train (fine tune a pre-trained Neural algorithmic processor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f7c779-c60a-4e25-8417-89af52749702",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processor_1.load_state_dict(torch.load('GENNARO-processor.pt'))\n",
    "processor_1.eval()\n",
    "\n",
    "# Freeze the pre-trained processor\n",
    "for param in processor_1.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3ddaf9-58b7-4a27-ad2b-0b0760d91adb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(n_epochs)):\n",
    "\n",
    "    # TRAIN\n",
    "    encoder.train()\n",
    "    decoder_1_b.train()\n",
    "\n",
    "    # reset conf Mats\n",
    "    cs_cm_1 = torch.zeros(\n",
    "        [max_prototype_buffer, max_prototype_buffer],\n",
    "        device=device)\n",
    "    os_cm_1 = torch.zeros([2, 2], device=device)\n",
    "\n",
    "    # reset metrics dict\n",
    "    metrics_dict = utils.reset_metrics_dict()\n",
    "\n",
    "    # go!\n",
    "    for batch_idx, sample_batch in enumerate(train_loader):\n",
    "        # go to cuda:\n",
    "        sample_batch = sample_batch[0].to(device), sample_batch[1].to(device)\n",
    "\n",
    "        # PHASE 1\n",
    "        proc_loss, \\\n",
    "            os_loss, \\\n",
    "            hiddens_1, \\\n",
    "            decoded_1 = first_phase_simple(\n",
    "                                sample_batch)\n",
    "\n",
    "        # Learning\n",
    "        processor_optimizer.zero_grad()\n",
    "        proc_loss.backward()\n",
    "        processor_optimizer.step()\n",
    "\n",
    "        os_loss = os_loss\n",
    "        os_optimizer.zero_grad()\n",
    "        os_loss.backward()\n",
    "        os_optimizer.step()\n",
    "\n",
    "        # Reporting\n",
    "        step = batch_idx + (epoch * len(train_loader))\n",
    "\n",
    "        if step % report_step_frequency == 0:\n",
    "            utils.reporting_gennaro(\n",
    "                'train',\n",
    "                epoch,\n",
    "                metrics_dict,\n",
    "                step,\n",
    "                wb,\n",
    "                wandb)\n",
    "\n",
    "    pu.super_plotting_function_gennaro(\n",
    "                phase='Training',\n",
    "                labels=sample_batch[1].cpu(),\n",
    "                hiddens_1=hiddens_1.detach().cpu(),\n",
    "                scores_1=decoded_1.detach().cpu(),\n",
    "                cs_cm_1=cs_cm_1.cpu(),\n",
    "                os_cm_1=os_cm_1.cpu(),\n",
    "                wb=wb,\n",
    "                wandb=wandb,\n",
    "                complete_classes=classes,\n",
    "                )\n",
    "\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        # Evaluation\n",
    "        encoder.eval()\n",
    "        decoder_1_b.eval()\n",
    "\n",
    "        # reset conf Mats\n",
    "        cs_cm_1 = torch.zeros(\n",
    "            [max_prototype_buffer, max_prototype_buffer],\n",
    "            device=device)\n",
    "        os_cm_1 = torch.zeros([2, 2], device=device)\n",
    "\n",
    "        # reset metrics dict\n",
    "        metrics_dict = utils.reset_metrics_dict()\n",
    "\n",
    "        # go!\n",
    "        for batch_idx, sample_batch in enumerate(test_loader):\n",
    "            # go to cuda:\n",
    "            sample_batch = sample_batch[0].to(device), sample_batch[1].to(device)\n",
    "\n",
    "            # PHASE 1\n",
    "            proc_1_loss, \\\n",
    "                os_1_loss, \\\n",
    "                hiddens_1, \\\n",
    "                decoded_1 = first_phase_simple(\n",
    "                                    sample_batch)\n",
    "\n",
    "            # Reporting\n",
    "            step = batch_idx + (epoch * len(test_loader))\n",
    "\n",
    "            if step % report_step_frequency == 0:\n",
    "                utils.reporting_gennaro(\n",
    "                    'eval',\n",
    "                    epoch,\n",
    "                    metrics_dict,\n",
    "                    step,\n",
    "                    wb,\n",
    "                    wandb)\n",
    "\n",
    "        pu.super_plotting_function_gennaro(\n",
    "                phase='Evaluation',\n",
    "                labels=sample_batch[1].cpu(),\n",
    "                hiddens_1=hiddens_1.detach().cpu(),\n",
    "                scores_1=decoded_1.detach().cpu(),\n",
    "                cs_cm_1=cs_cm_1.cpu(),\n",
    "                os_cm_1=os_cm_1.cpu(),\n",
    "                wb=wb,\n",
    "                wandb=wandb,\n",
    "                complete_classes=classes,\n",
    "            )\n",
    "\n",
    "        # Checking for improvement\n",
    "        curr_TNR = utils.get_balanced_accuracy(\n",
    "                pos_labels=sample_batch[1][:, 1].long(),\n",
    "                n_tasks=n_eval_tasks,\n",
    "                os_cm=os_cm_1,\n",
    "                n_w=balanced_acc_n_w\n",
    "                )\n",
    "\n",
    "        if curr_TNR > max_eval_TNR:\n",
    "            max_eval_TNR = curr_TNR\n",
    "            epochs_without_improvement = 0\n",
    "            save_stuff(run_name)\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f'Early stopping at episode {step}')\n",
    "            if wb:\n",
    "                wandb.log({'Early stopping at episode': step})\n",
    "            break\n",
    "\n",
    "if wb:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa7871c-7f9c-4920-9995-e32c65b9b5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
